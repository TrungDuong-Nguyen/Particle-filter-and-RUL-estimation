
\chapter{Base mathématique du filtre particulaire}

Dans ce chapitre on présente l'approche Bayésienne pour le problème
d'estimation ainsi que l'utilisation d'une technique d'approximation
numérique de type Monte Carlo. Enfin, un algorithme général du filtre
particulaire est donné dans la section \textcolor{red}{\ref{subsec:SIS filtre particulaire}}.

\section{Estimation Bayésienne}

Le but est d'estimer de façon récursive l'état caché $\left(x_{t}\right)_{t\geq0}$
au vu des observations $\left(y_{0},\,\ldots,\,y_{t}\right)$. L'estimation
Bayésienne récursive consiste deux phases: prédiction et correction
(mise à jour). Dans la phase de prédiction, suppose que l'on dispose
déjà la loi a posteriori\textit{ }$p\left(X_{t-1}\mid Y_{t-1}\right)$,
on peut trouver la loi a priori\textit{ $p\left(x_{t}\mid Y_{t-1}\right)$
}à l'instant $\left(t\right)$ en utilisant l'équation Chapman - Kolmogorov:
\begin{equation}
p\left(x_{t}\mid Y_{t-1}\right)=\int p\left(x_{t}\mid x_{t-1},\,Y_{t-1}\right)\times p\left(x_{t-1}\mid Y_{t-1}\right)dx_{t-1}=\int p\left(x_{t}\mid x_{t-1}\right)\times p\left(x_{t-1}\mid Y_{t-1}\right)dx_{t-1}\label{eq:pr=0000E9diction}
\end{equation}
Dans la deuxième phase, afin de corriger la prédiction, on fait appel
à la fonction de vraisemblance qui tient compte de la nouvelle valeur
de mesure $\left(y_{t}\right)$. La loi \textit{a posteriori} $p\left(x_{t}\mid Y_{t}\right)$
est calculée à l'aide de la formule suivante:
\begin{equation}
p\left(x_{t}\mid Y_{t}\right)=\frac{p\left(y_{t}\mid x_{t}\right)\times p\left(x_{t}\mid Y_{t-1}\right)}{p\left(y_{t}\mid Y_{t-1}\right)}=\frac{p\left(y_{t}\mid x_{t}\right)\times p\left(x_{t}\mid Y_{t-1}\right)}{\int p\left(y_{t}\mid x_{t}\right)\times p\left(x_{t}\mid Y_{t-1}\right)dx_{t}}\label{eq:correction}
\end{equation}
Le principe de l'estimation Bayésienne est présenté dans la figure
\textcolor{red}{\ref{fig:Principe de l'estimation Bay=0000E9sienne}}\textcolor{black}{.}

\begin{figure}
\begin{centering}
\includegraphics[scale=0.75]{\string"Figures/Bayesian Estimation (2)\string".eps}
\par\end{centering}
\caption{\label{fig:Principe de l'estimation Bay=0000E9sienne}Deux phases
de l'estimation Bayésienne}
\end{figure}
Enfin, après avoir obtenu la loi a posteriori, le niveau de dégradation
$\left(x_{t}\right)$ est déterminé par un estimateur dit minimum
de l'erreur quadratique moyenne:
\[
x_{MMSE}=\int x_{t}\times p\left(x_{t}\mid Y_{t}\right)dx_{t}
\]
Pourtant, on n'obtient que le calcul analytique des intégrations\textcolor{blue}{{}
\eqref{eq:pr=0000E9diction}} et \textcolor{blue}{\eqref{eq:correction}}
dans très peu de cas particuliers (par exemple $f\left(.\right)$
et $h\left(.\right)$ sont linéaires, $\left(v_{t}\right)$ et $\left(\varepsilon_{t}\right)$
sont Gaussiens). Donc, on se propose d'utiliser la méthode de Monte
Carlo qui offre une approximation des intégrations. La section \textcolor{red}{\ref{sec:M=0000E9thode de Monte Carlo}}
donne des interprétations mathématiques de cette méthode, ce qui nous
aide à comprendre comment le filtre particulaire est construit.

\section{Méthode de Monte Carlo\label{sec:M=0000E9thode de Monte Carlo}}

\subsection{Échantillonnage d'importance}

L'idée de base de la méthode de Monte Carlo consiste à utiliser la
technique d'\textit{échantillonnage d'importance}. Cette technique
permet d'approcher l'intégration d'une densité de probabilité grâce
à un ensemble des variables aléatoires générées selon une loi appelée
\textit{loi d'importance}. 

Soit $p\left(x\right)$ une densité de probabilité et $f\left(x\right)$
une fonction quelconque, on considère l'intégration suivante:
\begin{equation}
E_{p}\left\{ f\left(x\right)\right\} =\int f\left(x\right)\times p\left(x\right)dx\label{eq:int=0000E9gration 1}
\end{equation}
Si $p\left(x\right)$est plutôt complexe, il est nécessaire d'approcher
cette intégration au lieu d'intégrer directement. Comme il est difficile
d'échantillonner selon $p\left(x\right)$, on peut échantillonner
selon une loi $q\left(x\right)$ qui est plus simple, i.e:
\[
X\left(i\right)\,{\normalcolor \sim}\,q\left(x\right),\,i=1:N_{s}
\]
Ainsi: 
\begin{equation}
q\left(x\right)\approx\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta(x-X\left(i\right))\label{eq:approximation q(x)}
\end{equation}
où $\delta$ est la distribution de Dirac.

La loi des grands nombres assure que l'approximation \textcolor{blue}{\eqref{eq:approximation q(x)}}
converge presque sûr à $q\left(x\right)$ lorsque $N_{s}\rightarrow\infty$:
\[
\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta(x-X\left(i\right))\rightarrow q\left(x\right)
\]
En utilisant \textcolor{blue}{\eqref{eq:approximation q(x)}} et la
propriété de la distribution Dirac, l'intégration \textcolor{blue}{\eqref{eq:int=0000E9gration 1}}
est équivalent à:
\begin{eqnarray}
E_{p}\left\{ f\left(x\right)\right\}  & = & \int f\left(x\right)\times p\left(x\right)dx=\int f\left(x\right)\times\left(\frac{p\left(x\right)}{q(x)}\right)\times q\left(x\right)dx\nonumber \\
 & \approx & \int f\left(x\right)\times\left(\frac{p\left(x\right)}{q(x)}\right)\times\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta(x-X\left(i\right))dx\nonumber \\
 & \approx & \frac{1}{N_{s}}\sum_{i=1}^{N_{s}}f\left(X\left(i\right)\right)\times\left(\frac{p\left(X\left(i\right)\right)}{q\left(X\left(i\right)\right)}\right)\label{eq:int=0000E9gratiion 3}
\end{eqnarray}
Dans ce cas $q\left(x\right)$ est appelé loi d'importance\textit{.
}Le choix de la loi d'importance\textit{ }contribue le plus à la performance
de la technique d'échantillonnage d'importance. En effet, à condition
de pouvoir simuler selon $q\left(x\right)$, plus $q\left(x\right)$
approche $p\left(x\right)$ , plus le filtre particulaire est efficient.

De même, considère l'intégration:
\[
E_{p}\left\{ f\left(X_{t}\right)\right\} =\int f\left(X_{t}\right)\times p\left(X_{t}\mid Y_{t}\right)dX_{t}
\]
On souhaite approcher cette intégration alors que l'on sait seulement
échantillonner selon $q\left(X_{t}\mid Y_{t}\right)$ au lieu de $p\left(X_{t}\mid Y_{t}\right)$.
L'intégration ci-dessus peut être ré-écrit:
\[
E_{p}\left\{ f\left(X_{t}\right)\right\} =\int f\left(X_{t}\right)\times\left[\frac{p\left(X_{t}\mid Y_{t}\right)}{q\left(X_{t}\mid Y_{t}\right)}\right]\times q\left(X_{t}\mid Y_{t}\right)dX_{t}
\]
Grâce à la formule de Bayes:
\[
p\left(X_{t}\mid Y_{t}\right)=\frac{p\left(Y_{t}\mid X_{t}\right)\times p\left(X_{t}\right)}{p\left(Y_{t}\right)}
\]
on obtient: 
\begin{eqnarray*}
E_{p}\left\{ f\left(X_{t}\right)\right\}  & = & \frac{1}{p\left(Y_{t}\right)}\int f\left(X_{t}\right)\times\left[\frac{p\left(Y_{t}\mid X_{t}\right)\times p\left(X_{t}\right)}{q\left(X_{t}\mid Y_{t}\right)}\right]\times q\left(X_{t}\mid Y_{t}\right)dX_{t}\\
 & = & \frac{1}{\int p\left(Y_{t}\mid X_{t}\right)\times p\left(X_{t}\right)dX_{t}}\times\int f\left(X_{t}\right)\times\left[\frac{p\left(Y_{t}\mid X_{t}\right)\times p\left(X_{t}\right)}{q\left(X_{t}\mid Y_{t}\right)}\right]\times q\left(X_{t}\mid Y_{t}\right)dX_{t}
\end{eqnarray*}
En introduisant un facteur dit \textit{poids d'importance} égale à
la partie dans le crochet:
\begin{equation}
\omega_{t}=\frac{p\left(Y_{t}\mid X_{t}\right)\times p\left(X_{t}\right)}{q\left(X_{t}\mid Y_{t}\right)}\label{eq:poids d'importance IS}
\end{equation}
l'intégration au dessus peut être simplifiée à:
\begin{equation}
E_{p}\left\{ f\left(X_{t}\right)\right\} =\frac{\int\omega_{t}\times f\left(X_{t}\right)\times q\left(X_{t}\mid Y_{t}\right)dX_{t}}{\int\omega_{t}\times q\left(X_{t}\mid Y_{t}\right)dX_{t}}\label{eq:int=0000E9gration 4}
\end{equation}
Si on génère $\left(N_{s}\right)$ échantillons selon la loi d'importance\textit{
$q\left(X_{t}\mid Y_{t}\right)$}: $X_{t}^{i}\sim q\left(X_{t}\mid Y_{t}\right)$,
d'où $q\left(X_{t}\mid Y_{t}\right)\approx\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta\left(X_{t}-X_{t}^{i}\right)$,
en reprenant le résultat \textcolor{blue}{\eqref{eq:int=0000E9gratiion 3}}
l'espérance \textcolor{blue}{\eqref{eq:int=0000E9gration 4}} devient:
\[
E_{p}\left\{ f\left(X_{t}\right)\right\} \approx\frac{\int\omega_{t}\times f\left(X_{t}\right)\times\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta\left(X_{t}-X_{t}^{i}\right)dX_{t}}{\int\omega_{t}\times\frac{1}{N_{s}}\sum_{i=1}^{N_{s}}\delta\left(X_{t}-X_{t}^{i}\right)dX_{t}}\approx\frac{\sum_{i=1}^{N_{s}}\omega_{t}^{i}\times f\left(X_{t}^{i}\right)}{\sum_{i=1}^{N_{s}}\omega_{t}^{i}}
\]
De plus, si le \textit{poids d'importance normalisé} est défini telle
que:
\[
\text{W}_{t}^{i}=\frac{\omega_{t}^{i}}{\sum_{i=1}^{N_{s}}\omega_{t}^{i}}
\]
où $\omega_{t}^{i}=\frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{q\left(X_{t}^{i}\mid Y_{t}\right)}$,
on obtient finalement l'approximation:
\[
E_{p}\left\{ f\left(X_{t}\right)\right\} =\int f\left(X_{t}\right)\times p\left(X_{t}\mid Y_{t}\right)dX_{t}\approx\sum_{i=1}^{N_{s}}\text{W}_{t}^{i}\times f\left(X_{t}^{i}\right)
\]
à partir de laquelle on peut déduire l'approximation de la loi a posteriori:
\begin{equation}
p\left(X_{t}\mid Y_{t}\right)\approx\sum_{i=1}^{N_{e}}\text{W}_{t}^{i}\times\delta\left(X_{t}-X_{t}^{i}\right)\label{eq:loi a posteriori 1}
\end{equation}
avec $\sum_{i=1}^{N_{s}}\text{W}_{t}^{i}=1$

On peut voir que la loi a posteriori $p\left(X_{t}\mid Y_{t}\right)$
est approchée par une distribution discrète pondérée caractérisée
par un ensemble des particules $\left\{ X_{t}^{i},\text{W}_{t}^{i}\right\} _{i=1}^{N_{s}}$.

\subsection{Échantillonnage d'importance séquentielle}

La technique d'échantillonnage d'importance est inappopriée pour le
problème d'estimation récursive à cause du calcul coûteux du poids
d'importance\textit{. }En effet, chaque fois qu'une nouvelle valeur
de mesure $\left(y_{t}\right)$ est disponible, le re-calcul du poids
d'importance\textit{ }selon la formule \textcolor{blue}{\eqref{eq:poids d'importance IS}}
est vraiment pénible car on doit prendre en compte tous les valeurs
de mesures dans le passé $\left(Y_{t-1}\right)$ ainsi que tous les
états $\left(X_{t}\right)$. La technique d'échantillonnage d'importance
séquentielle (\textit{sequential important sampling} - SIS en anglais)
est introduite pour traiter ce problème.

L'idée de la technique SIS est interprétée comme suit: Suppose que
l'on dispose un ensemble de particules $\left\{ X_{t-1}^{i},\text{W}_{t-1}^{i}\right\} _{i=1}^{N_{s}}$
qui approche la distribution a posteriori $p\left(X_{t-1}\mid Y_{t-1}\right)$.
À l'acquisition de $\left(y_{t}\right)$, on souhaite approcher $p\left(X_{t}\mid Y_{t}\right)$
en propageant chaque particule de l'ensemble $\left\{ X_{t-1}^{i},\text{W}_{t-1}^{i}\right\} _{i=1}^{N_{s}}$
suivant deux étapes: muter (prédire) les échantillons $\left\{ X_{t-1}^{i}\right\} _{i=1}^{N_{s}}$,
puis mettre à jour leurs poids d'importances\textit{ $\left\{ \text{W}_{t-1}^{i}\right\} _{i=1}^{N_{s}}$
}correspondants. De cette manière, la technique d'échantillonnage
d'importance doit être modifiée de telle sorte que l'on peut approcher
$p\left(X_{t-1}\mid Y_{t-1}\right)$ à l'aide des poids d'importances
$\left\{ \text{W}_{t-1}^{i}\right\} _{i=1}^{N_{s}}$ et puis $p\left(X_{t}\mid Y_{t}\right)$
avec des nouveaux poids $\left\{ \text{W}_{t}^{i}\right\} _{i=1}^{N_{s}}$.
Cette procédure est réalisé séquentiellement en faisant appel à une
suite de loi d'importance\textit{ }telle que $X_{t-1}^{i}\sim q\left(X_{t-1}\mid Y_{t-1}\right)$,
$X_{t}^{i}\sim q\left(X_{t}\mid Y_{t}\right)$ et ainsi de suite. 

On s'intéresse maintenant à comment entraîner l'approximation séquentielle
de la loi a posteriori. Reprend l'équation \textcolor{blue}{\eqref{eq:poids d'importance IS}},
on décompose la forme simplifiée de son dénominateur:
\begin{eqnarray*}
q\left(X_{t}\mid Y_{t}\right) & = & q\left(x_{t},X_{t-1}\mid Y_{t}\right)=\frac{q\left(x_{t},X_{t-1},Y_{t}\right)}{q\left(Y_{t}\right)}\\
 & = & \frac{q\left(x_{t}\mid X_{t-1},Y_{t}\right)\times q\left(X_{t-1},Y_{t}\right)}{q\left(Y_{t}\right)}\\
 & = & q\left(x_{t}\mid X_{t-1},Y_{t}\right)\times\frac{q\left(X_{t-1}\mid Y_{t}\right)\times q\left(Y_{t}\right)}{q\left(Y_{t}\right)}\\
 & = & q\left(x_{t}\mid X_{t-1},Y_{t}\right)\times q\left(X_{t-1}\mid Y_{t}\right)\\
 & = & q\left(x_{t}\mid X_{t-1},Y_{t}\right)\times q\left(X_{t-1}\mid y_{t},Y_{t-1}\right)
\end{eqnarray*}
Comme les états au passé $\left(X_{t-1}\right)$ sont indépendants
de l'observation courante $\left(y_{t}\right)$, donc $q\left(X_{t-1}\mid y_{t},Y_{t-1}\right)=q\left(X_{t-1}\mid Y_{t-1}\right)$.
Alors:
\[
q\left(X_{t}\mid Y_{t}\right)=q\left(X_{t-1}\mid Y_{t-1}\right)\times q\left(x_{t}\mid X_{t-1},Y_{t}\right)
\]
En utilisant cette équation, on obtient l'extension\textit{ }de\textit{
}\textit{\textcolor{blue}{\eqref{eq:poids d'importance IS}}}:
\begin{eqnarray}
\omega_{t}^{i} & = & \frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{q\left(X_{t}^{i}\mid Y_{t}\right)}=\frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{q\left(X_{t-1}^{i}\mid Y_{t-1}\right)\times q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}\nonumber \\
 & = & \frac{\left[p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p\left(X_{t-1}^{i}\right)\right]}{q\left(X_{t-1}^{i}\mid Y_{t-1}\right)}\times\frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{\left[p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p\left(X_{t-1}^{i}\right)\right]\times q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}\nonumber \\
 & = & \omega_{t-1}^{i}\times\frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p\left(X_{t-1}^{i}\right)\times q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}\label{eq:poids d'importance SIS 1}
\end{eqnarray}
où on peut facilement trouver que le poids d'importance est mise à
jour récursivement.

On fait attention à deux densités $p\left(Y_{t}\mid X_{t}^{i}\right)$
et $p\left(X_{t}^{i}\right)$ du numérateur. Tout d'abord, on décompose
$p\left(X_{t}^{i}\right)$ en faisant appel à la propriété Markovien
\textcolor{blue}{\eqref{eq:hypoth=0000E8se 1}} de $\left(X_{t}\right)$:
\begin{equation}
p(X_{t}^{i})=p(x_{t}^{i},X_{t-1}^{i})=p(x_{t}^{i}\mid X_{t-1}^{i})\times p(X_{t-1}^{i})=p(x_{t}^{i}\mid x_{t-1}^{i})\times p(X_{t-1}^{i})\label{eq:num=0000E9rateur 1}
\end{equation}
Par ailleurs, l'extension de la formule de Bayes $p\left(AB\mid C\right)=p\left(A\mid BC\right)\times p\left(B\mid C\right)$
nous donne l'expression:
\[
p\left(Y_{t}\mid X_{t}^{i}\right)=p\left(y_{t},Y_{t-1}\mid x_{t}^{i},X_{t-1}^{i}\right)=p\left(y_{t}\mid Y_{t-1},x_{t}^{i},X_{t-1}^{i}\right)\times p\left(Y_{t-1}\mid x_{t}^{i},X_{t-1}^{i}\right)
\]
L'hypothèse \textcolor{blue}{\eqref{eq:hypoth=0000E8se 2}} et le
fait que des observations au passé $\left(Y_{t-1}\right)$ sont indépendantes
avec l'état courant $\left(x_{t}\right)$ favorisent respectivement
des simplifications suivantes:
\[
\begin{cases}
p\left(y_{t}\mid Y_{t-1},x_{t}^{i},X_{t-1}^{i}\right) & =p\left(y_{t}\mid x_{t}^{i}\right)\\
p\left(Y_{t-1}\mid x_{t}^{i},X_{t-1}^{i}\right) & =p\left(Y_{t-1}\mid X_{t-1}^{i}\right)
\end{cases}
\]
Par conséquent:
\begin{equation}
p\left(Y_{t}\mid X_{t}^{i}\right)=p\left(y_{t}\mid Y_{t-1},x_{t}^{i},X_{t-1}^{i}\right)\times p\left(Y_{t-1}\mid x_{t}^{i},X_{t-1}^{i}\right)=p\left(y_{t}\mid x_{t}^{i}\right)\times p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\label{eq:num=0000E9rateur 2}
\end{equation}
Subtituer \textcolor{blue}{\eqref{eq:num=0000E9rateur 1}} et \textcolor{blue}{\eqref{eq:num=0000E9rateur 2}}
à \textcolor{blue}{\eqref{eq:poids d'importance SIS 1}}, on obtient\textit{:
\begin{eqnarray*}
\omega_{t}^{i} & = & \omega_{t-1}^{i}\times\frac{p\left(Y_{t}\mid X_{t}^{i}\right)\times p\left(X_{t}^{i}\right)}{p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p\left(X_{t-1}^{i}\right)\times q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}\\
 & = & \omega_{t-1}^{i}\times\frac{p\left(y_{t}\mid x_{t}^{i}\right)\times p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p(x_{t}^{i}\mid x_{t-1}^{i})\times p(X_{t-1}^{i})}{p\left(Y_{t-1}\mid X_{t-1}^{i}\right)\times p\left(X_{t-1}^{i}\right)\times q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}\\
 & = & \omega_{t-1}^{i}\times\frac{p\left(y_{t}\mid x_{t}^{i}\right)\times p(x_{t}^{i}\mid x_{t-1}^{i})}{q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)}
\end{eqnarray*}
}En outre, on peut reformuler $q\left(x_{t}^{i}\mid X_{t-1}^{i},Y_{t}\right)=q\left(x_{t}^{i}\mid x_{t-1}^{i},y_{t}\right)$
en supposant que la loi d'importance\textit{ }ne dépend que de l'état
précédent $\left(x_{t-1}\right)$ et de l'observation courante $\left(y_{t}\right)$.
Une telle supposition est raisonnable et paraît très commun dans le
contexte de filtrage. En effet, ce qu'on veut savoir véritablement
est une approximation de la loi a posteriori \textit{``marginale''
$p\left(x_{t}\mid Y_{t}\right)$ }à chaque instant $\left(t\right)$.
On peut voir dans le chapitre 3, que l'on n'est pas strictement obligé
de sauvegarder ni la trajectoire passée $\left\{ X_{t-1}^{i}\right\} _{i=1}^{N_{s}}$
ni les observations passées $\left\{ Y_{t-1}\right\} $ lors de la
programmation. Alors, l'expression de calcul du poids d'importance\textit{
}est:
\begin{equation}
\omega_{t}^{i}=\omega_{t-1}^{i}\times\frac{p\left(y_{t}\mid x_{t}^{i}\right)\times p(x_{t}^{i}\mid x_{t-1}^{i})}{q\left(x_{t}^{i}\mid x_{t-1}^{i},y_{t}\right)}\label{eq:poids d'importance SIS 2}
\end{equation}
La loi a posteriori\textit{ }est une modification de \textcolor{blue}{\eqref{eq:loi a posteriori 1}}:
\begin{equation}
p\left(x_{t}\mid Y_{t}\right)\approx\sum_{i=1}^{N_{e}}\text{W}_{t}^{i}\times\delta\left(x_{t}-x_{t}^{i}\right)\label{eq:loi a posteriori 2}
\end{equation}
dans laquelle $\text{W}_{t}^{i}=\frac{\omega_{t}^{i}}{\sum_{i=1}^{N_{s}}\omega_{t}^{i}}$
avec $\left(\omega_{t}^{i}\right)$ précisé dans l'équation \textcolor{blue}{\eqref{eq:poids d'importance SIS 2}}.

Le niveau de dégradation estimé est donc:
\[
x_{MMSE}=\int x_{t}\times p\left(x_{t}\mid Y_{t}\right)dx_{t}\approx\sum_{i=1}^{N_{s}}x_{t}\times\left(\text{W}_{t}^{i}\times\delta\left(x_{t}-x_{t}^{i}\right)\right)\approx\sum_{i=1}^{N_{s}}\text{W}_{t}^{i}\times x_{t}^{i}
\]


\subsection{Algorithme du SIS filtre particulaire \label{subsec:SIS filtre particulaire}}

On est maintenant capable de montrer dans l' \textcolor{red}{\ref{alg:Algorithme SIS filtre particulaire}}
les composants principaux d'un filtre particulaire SIS. On trouve
que c'est un algorithme de type génétique où un ensemble de particules
est propagé avec le temps.

\begin{algorithm}
\begin{centering}
À l'instant $(t=0)$\linebreak{}
\par\end{centering}
\begin{centering}
\textbf{Initialisation $\left(i=1:N_{s}\right)$}\linebreak{}
\par\end{centering}
\begin{centering}
Générer un ensemble d'échantillons i.i.d selon la loi initiale:
\par\end{centering}
\begin{centering}
$x_{0}^{i}\sim p\left(x_{0}\right)$
\par\end{centering}
\begin{centering}
Assigner les poids d'importances:
\par\end{centering}
\begin{centering}
$\omega_{0}^{i}=\frac{1}{N_{s}}$
\par\end{centering}
\begin{centering}
---------------------------------------------------------------------
\par\end{centering}
\begin{centering}
À partir de l'instant $\left(t\geq1\right)$ , sachant que l'on dispose
un ensemble de particules $\left\{ x_{t-1}^{i},\omega_{t-1}^{i}\right\} _{i=1}^{N_{s}}$\linebreak{}
\par\end{centering}
\begin{centering}
\textbf{Échantillonnage d'importance}\linebreak{}
\par\end{centering}
\begin{centering}
Générer un nouvel ensemble des échantillons selon la loi d'importance:
\par\end{centering}
\begin{centering}
$x_{t}^{i}\sim q\left(x_{t}^{i}\mid x_{t-1}^{i},y_{t}\right),\,i=1:N_{s}$
\par\end{centering}
\begin{centering}
Déterminer la fonction de vraisemblance $p\left(y_{t}\mid x_{t}^{i}\right)$
et le noyau de transition $p\left(x_{t}^{i}\mid x_{t-1}^{i}\right)$,
puis calculer les poids d'importances\textit{ }selon la formule \textcolor{blue}{\eqref{eq:poids d'importance SIS 2}}.\linebreak{}
\par\end{centering}
\begin{centering}
\textbf{Normaliser}\linebreak{}
\par\end{centering}
\begin{centering}
$W_{t}^{i}=\frac{\omega_{t}^{i}}{\sum_{i=1}^{N_{s}}\omega_{t}^{i}},\text{ }i=1:N_{s}$\linebreak{}
\par\end{centering}
\begin{centering}
\textbf{Estimer le niveau de dégradation}\linebreak{}
\par\end{centering}
\begin{centering}
$x_{MMSE}\approx\sum_{i=1}^{N_{s}}W_{t}^{i}\times x_{t}^{i}$
\par\end{centering}
\caption{\label{alg:Algorithme SIS filtre particulaire}Algorithme du SIS filtre
particulaire}
\end{algorithm}

L'avantage du filtre particulaire est qu'il n'existe aucune restriction
de la forme de deux fonctions $f\left(.\right)$ et $h\left(.\right)$
(linéaire ou non linéaire) ainsi que le type de bruit $\left(v_{t}\right)$
et $\left(\varepsilon{}_{t}\right)$ (Gaussien ou non Gaussien) dans
le modèle d'espace d'état \textcolor{blue}{\eqref{eq:Mod=0000E8le g=0000E9n=0000E9ral}}.
Pour mettre en oeuvre l'algorithme décrit ci dessus, il est nécessaire
de savoir:
\begin{itemize}
\item simuler selon la loi intiale $p\left(x_{0}\right)$
\item simuler selon la loi d'importance $q\left(x_{t}\mid x_{t-1},y_{t}\right)$
\item calculer la vraisemblance $p\left(y_{t}\mid x_{t}\right)$ pour tout
$\left(x_{t}\right)$ à l'acquisiton de $\left(y_{t}\right)$
\end{itemize}

